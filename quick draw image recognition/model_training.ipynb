{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9032\\305245093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \"\"\"\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes.DType\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DType\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m class DType(\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0m_dtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTraceType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rashi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36mDType\u001b[1;34m()\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m   \u001b[1;32mdef\u001b[0m \u001b[0mexperimental_type_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mType\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypes_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializedDType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"Returns the type of proto associated with DType serialization.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializedDType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 30\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "TRAIN_PATH = 'shapes'\n",
    "VAL_PATH = 'val_shapes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 860 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data =  tf.keras.utils.image_dataset_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    directory=TRAIN_PATH,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data =  tf.keras.utils.image_dataset_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    directory=VAL_PATH,\n",
    "    shuffle=True,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_data.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    #print(images[i].numpy().max())\n",
    "    plt.imshow(images[i].numpy(),cmap='gray' )\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 30, 30, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 6915      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,731\n",
      "Trainable params: 25,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "from tensorflow.keras import layers\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(IMG_HEIGHT,IMG_WIDTH,1)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation=\"softmax\"),\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',              \n",
    "              loss=\"sparse_categorical_crossentropy\",              \n",
    "              metrics=['accuracy'])\n",
    "# print the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "27/27 [==============================] - 3s 70ms/step - loss: 19.4708 - accuracy: 0.3198 - val_loss: 1.2048 - val_accuracy: 0.3730\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.1293 - accuracy: 0.3198 - val_loss: 1.1047 - val_accuracy: 0.3016\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.1011 - accuracy: 0.3221 - val_loss: 1.1008 - val_accuracy: 0.3373\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0944 - accuracy: 0.3663 - val_loss: 1.1067 - val_accuracy: 0.2976\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0865 - accuracy: 0.3767 - val_loss: 1.1126 - val_accuracy: 0.3016\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0988 - accuracy: 0.3523 - val_loss: 1.1000 - val_accuracy: 0.3413\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0916 - accuracy: 0.3605 - val_loss: 1.1050 - val_accuracy: 0.2778\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0905 - accuracy: 0.3407 - val_loss: 1.0967 - val_accuracy: 0.2976\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0849 - accuracy: 0.3698 - val_loss: 1.1009 - val_accuracy: 0.3016\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0815 - accuracy: 0.3721 - val_loss: 1.1094 - val_accuracy: 0.3135\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0852 - accuracy: 0.3767 - val_loss: 1.0990 - val_accuracy: 0.2817\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0900 - accuracy: 0.3523 - val_loss: 1.1049 - val_accuracy: 0.2619\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0888 - accuracy: 0.3814 - val_loss: 1.1071 - val_accuracy: 0.3056\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0816 - accuracy: 0.3907 - val_loss: 1.0885 - val_accuracy: 0.3532\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0825 - accuracy: 0.3698 - val_loss: 1.0934 - val_accuracy: 0.3214\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0759 - accuracy: 0.3674 - val_loss: 1.0999 - val_accuracy: 0.2857\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0787 - accuracy: 0.4047 - val_loss: 1.0895 - val_accuracy: 0.3452\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0831 - accuracy: 0.3849 - val_loss: 1.0960 - val_accuracy: 0.2857\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0744 - accuracy: 0.3814 - val_loss: 1.0762 - val_accuracy: 0.3690\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0748 - accuracy: 0.3674 - val_loss: 1.0795 - val_accuracy: 0.3373\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0643 - accuracy: 0.3721 - val_loss: 1.0829 - val_accuracy: 0.3294\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0622 - accuracy: 0.3814 - val_loss: 1.0687 - val_accuracy: 0.3889\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0504 - accuracy: 0.4070 - val_loss: 1.0423 - val_accuracy: 0.4762\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0577 - accuracy: 0.4174 - val_loss: 1.0822 - val_accuracy: 0.4127\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0651 - accuracy: 0.3767 - val_loss: 1.0731 - val_accuracy: 0.4048\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0573 - accuracy: 0.4000 - val_loss: 1.0740 - val_accuracy: 0.3651\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0427 - accuracy: 0.4314 - val_loss: 1.0699 - val_accuracy: 0.4683\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0667 - accuracy: 0.4035 - val_loss: 1.0862 - val_accuracy: 0.3690\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0890 - accuracy: 0.3733 - val_loss: 1.0847 - val_accuracy: 0.3333\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0852 - accuracy: 0.3651 - val_loss: 1.0819 - val_accuracy: 0.3889\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0667 - accuracy: 0.3721 - val_loss: 1.0487 - val_accuracy: 0.3532\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0457 - accuracy: 0.4116 - val_loss: 1.0352 - val_accuracy: 0.4286\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.0640 - accuracy: 0.4244 - val_loss: 1.0400 - val_accuracy: 0.4087\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0519 - accuracy: 0.3965 - val_loss: 1.0647 - val_accuracy: 0.3849\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0388 - accuracy: 0.4221 - val_loss: 1.0150 - val_accuracy: 0.4365\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0054 - accuracy: 0.4593 - val_loss: 1.0196 - val_accuracy: 0.4563\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0172 - accuracy: 0.4651 - val_loss: 1.0047 - val_accuracy: 0.4960\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.9944 - accuracy: 0.4837 - val_loss: 1.0289 - val_accuracy: 0.4484\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.9891 - accuracy: 0.4860 - val_loss: 0.9996 - val_accuracy: 0.4524\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 2s 51ms/step - loss: 0.9628 - accuracy: 0.5058 - val_loss: 0.9953 - val_accuracy: 0.4643\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 2s 53ms/step - loss: 0.9665 - accuracy: 0.4849 - val_loss: 0.9978 - val_accuracy: 0.5198\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 2s 50ms/step - loss: 0.9672 - accuracy: 0.5035 - val_loss: 0.9465 - val_accuracy: 0.5437\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.9669 - accuracy: 0.5279 - val_loss: 0.9570 - val_accuracy: 0.5040\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 2s 52ms/step - loss: 0.9194 - accuracy: 0.5198 - val_loss: 0.9356 - val_accuracy: 0.5397\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 2s 54ms/step - loss: 0.9098 - accuracy: 0.5616 - val_loss: 0.9305 - val_accuracy: 0.5357\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 2s 51ms/step - loss: 0.9702 - accuracy: 0.5384 - val_loss: 0.8818 - val_accuracy: 0.5833\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 2s 54ms/step - loss: 0.9305 - accuracy: 0.5488 - val_loss: 0.8878 - val_accuracy: 0.5317\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 2s 53ms/step - loss: 0.9238 - accuracy: 0.5814 - val_loss: 0.8745 - val_accuracy: 0.5952\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 2s 52ms/step - loss: 0.8841 - accuracy: 0.5802 - val_loss: 0.8249 - val_accuracy: 0.5992\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 2s 53ms/step - loss: 0.8587 - accuracy: 0.6372 - val_loss: 0.8906 - val_accuracy: 0.5714\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 0.8487 - accuracy: 0.5895 - val_loss: 0.8403 - val_accuracy: 0.5913\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 2s 50ms/step - loss: 0.8637 - accuracy: 0.5907 - val_loss: 0.8374 - val_accuracy: 0.5992\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.8064 - accuracy: 0.6221 - val_loss: 0.8363 - val_accuracy: 0.6786\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.8366 - accuracy: 0.6302 - val_loss: 0.8154 - val_accuracy: 0.6944\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.8451 - accuracy: 0.6267 - val_loss: 0.7492 - val_accuracy: 0.6706\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7969 - accuracy: 0.6581 - val_loss: 0.7728 - val_accuracy: 0.6349\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.7979 - accuracy: 0.6628 - val_loss: 0.7608 - val_accuracy: 0.7024\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8295 - accuracy: 0.6163 - val_loss: 0.8265 - val_accuracy: 0.6071\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7809 - accuracy: 0.6872 - val_loss: 0.7633 - val_accuracy: 0.6429\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7543 - accuracy: 0.6733 - val_loss: 0.7470 - val_accuracy: 0.6825\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7398 - accuracy: 0.6849 - val_loss: 0.7057 - val_accuracy: 0.7063\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7438 - accuracy: 0.6779 - val_loss: 1.0229 - val_accuracy: 0.5476\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7862 - accuracy: 0.6674 - val_loss: 0.6983 - val_accuracy: 0.7262\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.7214 - accuracy: 0.7093 - val_loss: 0.7122 - val_accuracy: 0.7341\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6974 - accuracy: 0.7012 - val_loss: 0.7403 - val_accuracy: 0.6746\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7022 - accuracy: 0.7035 - val_loss: 0.6997 - val_accuracy: 0.7460\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7100 - accuracy: 0.7070 - val_loss: 0.7615 - val_accuracy: 0.6706\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.7156 - accuracy: 0.6884 - val_loss: 0.8391 - val_accuracy: 0.6508\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6968 - accuracy: 0.7023 - val_loss: 0.7048 - val_accuracy: 0.6905\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6550 - accuracy: 0.7395 - val_loss: 0.6870 - val_accuracy: 0.7262\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.6779 - accuracy: 0.7337 - val_loss: 0.7010 - val_accuracy: 0.6746\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6392 - accuracy: 0.7163 - val_loss: 0.6172 - val_accuracy: 0.7659\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5913 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 0.7421\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6231 - accuracy: 0.7302 - val_loss: 0.6634 - val_accuracy: 0.7222\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5718 - accuracy: 0.7523 - val_loss: 0.6402 - val_accuracy: 0.7381\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5876 - accuracy: 0.7616 - val_loss: 0.5976 - val_accuracy: 0.7897\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5928 - accuracy: 0.7558 - val_loss: 0.6135 - val_accuracy: 0.7579\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6000 - accuracy: 0.7558 - val_loss: 0.5388 - val_accuracy: 0.8095\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6028 - accuracy: 0.7395 - val_loss: 0.6595 - val_accuracy: 0.6944\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6074 - accuracy: 0.7512 - val_loss: 0.6867 - val_accuracy: 0.7024\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6804 - accuracy: 0.7174 - val_loss: 0.6818 - val_accuracy: 0.6944\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6288 - accuracy: 0.7279 - val_loss: 0.7592 - val_accuracy: 0.6865\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6421 - accuracy: 0.7384 - val_loss: 0.6192 - val_accuracy: 0.7262\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5359 - accuracy: 0.7826 - val_loss: 0.6028 - val_accuracy: 0.7460\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5544 - accuracy: 0.7779 - val_loss: 0.6309 - val_accuracy: 0.7302\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5156 - accuracy: 0.7872 - val_loss: 0.5396 - val_accuracy: 0.8095\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5365 - accuracy: 0.7744 - val_loss: 0.6023 - val_accuracy: 0.7460\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5135 - accuracy: 0.7860 - val_loss: 0.6158 - val_accuracy: 0.7817\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5545 - accuracy: 0.7826 - val_loss: 0.5823 - val_accuracy: 0.7659\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5657 - accuracy: 0.7709 - val_loss: 0.5970 - val_accuracy: 0.8175\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5112 - accuracy: 0.7895 - val_loss: 0.5797 - val_accuracy: 0.7857\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5081 - accuracy: 0.7895 - val_loss: 0.6322 - val_accuracy: 0.7619\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4923 - accuracy: 0.7860 - val_loss: 0.5212 - val_accuracy: 0.8452\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4920 - accuracy: 0.8023 - val_loss: 0.5047 - val_accuracy: 0.8214\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4721 - accuracy: 0.8140 - val_loss: 0.5003 - val_accuracy: 0.8294\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4294 - accuracy: 0.8267 - val_loss: 0.4630 - val_accuracy: 0.8571\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4666 - accuracy: 0.8186 - val_loss: 0.4899 - val_accuracy: 0.8651\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4488 - accuracy: 0.8209 - val_loss: 0.4933 - val_accuracy: 0.8651\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4626 - accuracy: 0.8267 - val_loss: 0.6399 - val_accuracy: 0.7222\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4905 - accuracy: 0.7977 - val_loss: 0.4840 - val_accuracy: 0.8413\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.4667 - accuracy: 0.8035 - val_loss: 0.4947 - val_accuracy: 0.8690\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4377 - accuracy: 0.8233 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4248 - accuracy: 0.8279 - val_loss: 0.4437 - val_accuracy: 0.8532\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3988 - accuracy: 0.8419 - val_loss: 0.4294 - val_accuracy: 0.8651\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3932 - accuracy: 0.8488 - val_loss: 0.5264 - val_accuracy: 0.8413\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3838 - accuracy: 0.8360 - val_loss: 0.4503 - val_accuracy: 0.8611\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4321 - accuracy: 0.8302 - val_loss: 0.5953 - val_accuracy: 0.7976\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4080 - accuracy: 0.8395 - val_loss: 0.4687 - val_accuracy: 0.8452\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3510 - accuracy: 0.8593 - val_loss: 0.5010 - val_accuracy: 0.8373\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.3802 - accuracy: 0.8523 - val_loss: 0.4132 - val_accuracy: 0.8373\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3708 - accuracy: 0.8605 - val_loss: 0.4004 - val_accuracy: 0.8730\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3822 - accuracy: 0.8419 - val_loss: 0.4300 - val_accuracy: 0.8730\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3352 - accuracy: 0.8733 - val_loss: 0.4207 - val_accuracy: 0.8730\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3776 - accuracy: 0.8547 - val_loss: 0.5152 - val_accuracy: 0.8214\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4195 - accuracy: 0.8314 - val_loss: 0.4726 - val_accuracy: 0.8413\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4077 - accuracy: 0.8349 - val_loss: 0.4820 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3825 - accuracy: 0.8442 - val_loss: 0.5346 - val_accuracy: 0.8373\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3605 - accuracy: 0.8709 - val_loss: 0.3969 - val_accuracy: 0.8730\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4192 - accuracy: 0.8395 - val_loss: 0.4858 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4004 - accuracy: 0.8593 - val_loss: 0.4543 - val_accuracy: 0.8690\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4027 - accuracy: 0.8419 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3872 - accuracy: 0.8465 - val_loss: 0.6662 - val_accuracy: 0.7857\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4549 - accuracy: 0.8198 - val_loss: 0.4168 - val_accuracy: 0.8651\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3431 - accuracy: 0.8628 - val_loss: 0.4147 - val_accuracy: 0.8690\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3087 - accuracy: 0.8709 - val_loss: 0.5105 - val_accuracy: 0.8452\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3149 - accuracy: 0.8767 - val_loss: 0.4482 - val_accuracy: 0.8532\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3598 - accuracy: 0.8663 - val_loss: 0.3991 - val_accuracy: 0.8690\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.3143 - accuracy: 0.8779 - val_loss: 0.4176 - val_accuracy: 0.8810\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3238 - accuracy: 0.8721 - val_loss: 0.5278 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.3360 - accuracy: 0.8744 - val_loss: 0.4123 - val_accuracy: 0.8611\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3175 - accuracy: 0.8814 - val_loss: 0.4508 - val_accuracy: 0.8730\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.2767 - accuracy: 0.8802 - val_loss: 0.4976 - val_accuracy: 0.8611\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2536 - accuracy: 0.9116 - val_loss: 0.3492 - val_accuracy: 0.8810\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2738 - accuracy: 0.9023 - val_loss: 0.3756 - val_accuracy: 0.8810\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2422 - accuracy: 0.9012 - val_loss: 0.4488 - val_accuracy: 0.8571\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2640 - accuracy: 0.9128 - val_loss: 0.4631 - val_accuracy: 0.8730\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2891 - accuracy: 0.8860 - val_loss: 0.4472 - val_accuracy: 0.8730\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3132 - accuracy: 0.8942 - val_loss: 0.4808 - val_accuracy: 0.8611\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3093 - accuracy: 0.8919 - val_loss: 0.3931 - val_accuracy: 0.8810\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2499 - accuracy: 0.9058 - val_loss: 0.4233 - val_accuracy: 0.8730\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2390 - accuracy: 0.9151 - val_loss: 0.4724 - val_accuracy: 0.8611\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2778 - accuracy: 0.8953 - val_loss: 0.5076 - val_accuracy: 0.8651\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2743 - accuracy: 0.8953 - val_loss: 0.4449 - val_accuracy: 0.8730\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3321 - accuracy: 0.8826 - val_loss: 0.4531 - val_accuracy: 0.8770\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3209 - accuracy: 0.8744 - val_loss: 0.4291 - val_accuracy: 0.8651\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2754 - accuracy: 0.8930 - val_loss: 0.5397 - val_accuracy: 0.8611\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2598 - accuracy: 0.9012 - val_loss: 0.4009 - val_accuracy: 0.8770\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2503 - accuracy: 0.9012 - val_loss: 0.4409 - val_accuracy: 0.8413\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2730 - accuracy: 0.8930 - val_loss: 0.4842 - val_accuracy: 0.8532\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2611 - accuracy: 0.8977 - val_loss: 0.4294 - val_accuracy: 0.8770\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.2471 - accuracy: 0.9035 - val_loss: 0.4117 - val_accuracy: 0.8810\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.2423 - accuracy: 0.9081 - val_loss: 0.4864 - val_accuracy: 0.8730\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2483 - accuracy: 0.8942 - val_loss: 0.4300 - val_accuracy: 0.8849\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2205 - accuracy: 0.9116 - val_loss: 0.4190 - val_accuracy: 0.8849\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2276 - accuracy: 0.9128 - val_loss: 0.4229 - val_accuracy: 0.8810\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.2761 - accuracy: 0.8988 - val_loss: 0.4105 - val_accuracy: 0.8651\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2501 - accuracy: 0.9047 - val_loss: 0.4585 - val_accuracy: 0.8730\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.2298 - accuracy: 0.9163 - val_loss: 0.4695 - val_accuracy: 0.8571\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2117 - accuracy: 0.9267 - val_loss: 0.5302 - val_accuracy: 0.8651\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2192 - accuracy: 0.9174 - val_loss: 0.5939 - val_accuracy: 0.8294\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2168 - accuracy: 0.9198 - val_loss: 0.6501 - val_accuracy: 0.8532\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2603 - accuracy: 0.9012 - val_loss: 0.4993 - val_accuracy: 0.8651\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2185 - accuracy: 0.9186 - val_loss: 0.4590 - val_accuracy: 0.8611\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2715 - accuracy: 0.8919 - val_loss: 0.5074 - val_accuracy: 0.8730\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.2254 - accuracy: 0.9093 - val_loss: 0.4407 - val_accuracy: 0.8849\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2282 - accuracy: 0.9128 - val_loss: 0.4009 - val_accuracy: 0.8770\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1807 - accuracy: 0.9314 - val_loss: 0.3727 - val_accuracy: 0.8929\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2356 - accuracy: 0.9186 - val_loss: 0.4330 - val_accuracy: 0.8690\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1957 - accuracy: 0.9267 - val_loss: 0.4952 - val_accuracy: 0.8770\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.2471 - accuracy: 0.9081 - val_loss: 0.4555 - val_accuracy: 0.8849\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1790 - accuracy: 0.9349 - val_loss: 0.4325 - val_accuracy: 0.8810\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1822 - accuracy: 0.9279 - val_loss: 0.5964 - val_accuracy: 0.8492\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.2007 - accuracy: 0.9291 - val_loss: 0.5203 - val_accuracy: 0.8651\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.1658 - accuracy: 0.9337 - val_loss: 0.3997 - val_accuracy: 0.9048\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1651 - accuracy: 0.9372 - val_loss: 0.5930 - val_accuracy: 0.8849\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1795 - accuracy: 0.9314 - val_loss: 0.3978 - val_accuracy: 0.8929\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1840 - accuracy: 0.9302 - val_loss: 0.5623 - val_accuracy: 0.8730\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1598 - accuracy: 0.9291 - val_loss: 0.5001 - val_accuracy: 0.8571\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1464 - accuracy: 0.9442 - val_loss: 0.4986 - val_accuracy: 0.8770\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2085 - accuracy: 0.9302 - val_loss: 0.5021 - val_accuracy: 0.8730\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2327 - accuracy: 0.9140 - val_loss: 0.4928 - val_accuracy: 0.8770\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2428 - accuracy: 0.9140 - val_loss: 0.4795 - val_accuracy: 0.8611\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2530 - accuracy: 0.9000 - val_loss: 0.5475 - val_accuracy: 0.8968\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2173 - accuracy: 0.9209 - val_loss: 0.4504 - val_accuracy: 0.8849\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1476 - accuracy: 0.9430 - val_loss: 0.5674 - val_accuracy: 0.8929\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1740 - accuracy: 0.9419 - val_loss: 0.4722 - val_accuracy: 0.8849\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2043 - accuracy: 0.9314 - val_loss: 0.4733 - val_accuracy: 0.8929\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1573 - accuracy: 0.9407 - val_loss: 0.6575 - val_accuracy: 0.8690\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1955 - accuracy: 0.9256 - val_loss: 0.4395 - val_accuracy: 0.8770\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.1948 - accuracy: 0.9302 - val_loss: 0.4575 - val_accuracy: 0.8849\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.1853 - accuracy: 0.9302 - val_loss: 0.5970 - val_accuracy: 0.8651\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1479 - accuracy: 0.9465 - val_loss: 0.4504 - val_accuracy: 0.8810\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1985 - accuracy: 0.9279 - val_loss: 0.5029 - val_accuracy: 0.8651\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2136 - accuracy: 0.9256 - val_loss: 0.3983 - val_accuracy: 0.8889\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.1519 - accuracy: 0.9407 - val_loss: 0.6167 - val_accuracy: 0.8770\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1868 - accuracy: 0.9233 - val_loss: 0.5752 - val_accuracy: 0.8968\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1517 - accuracy: 0.9465 - val_loss: 0.5516 - val_accuracy: 0.8968\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1620 - accuracy: 0.9465 - val_loss: 0.6754 - val_accuracy: 0.8770\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1508 - accuracy: 0.9488 - val_loss: 0.5755 - val_accuracy: 0.8889\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1636 - accuracy: 0.9384 - val_loss: 0.5000 - val_accuracy: 0.8532\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step\n",
      "[[1. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_data.take(1):\n",
    "    for i in range(1):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        #print(images[i].numpy().max())\n",
    "        plt.imshow(images[i].numpy(),cmap='gray' )\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "        print(np.round(model.predict(images[:1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAu0lEQVR4nO3SMWoCQRiG4XdmHXGxSGIpeIBcwmPkCDlGulReLVWwyhGUWAgSV3fnTREUd1c8QPDrhoef/5thgtxKvKl3/rd8qLnyM05c50EOfQ4CGELMFM0xdpb9HcejOKV8pnzj2HZVGZIoFOa2glrJYLlRf6o5ffaBD92Zq7wvcdXhQ7iYSWwvOALJ4lxlJ6N28yzl6UlMdSq6zeFTtza6f0zrqltNYMjsZTF5Gtt891h9fScEvtr38hdFbb7v/20/pgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=30x30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img_path = 'shapes/1/1681791001.jpg'\n",
    "img_path = 'shapes/2/1681770064.jpg'\n",
    "newimg = tf.keras.utils.load_img(\n",
    "    path=img_path,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(30,30),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")\n",
    "newimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "input_arr = tf.keras.utils.img_to_array(newimg)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "print(np.round(model.predict(input_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shapes_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shapes_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('shapes_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('shapes_v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
